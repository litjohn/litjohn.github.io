<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>下载 ComfyUI 记录 | 正确即是废话，废话亦是正确</title><meta name=keywords content><meta name=description content="
我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。
省流：垃圾

最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。

comfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。
主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。
我使用了它来运行 Z-image turbo。

下载非常简单。你需要访问官网，然后下载一个安装包。
有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。
下载之后无脑跟随指示。
然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。
可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。

之后点击 comfyUI.exe 启动。过程也很简单。
可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。

去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 modelscope。
实测这个仓库可用。
进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。
注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。
量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。
下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \models\ 中的 \diffusion_models，\text_encoders 和 \vae 中。
注意绝对不是 \ComfyUI\resources\ComfyUI\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。"><meta name=author content><link rel=canonical href=https://litjohn.github.io/posts/comfyui/><link crossorigin=anonymous href=/assets/css/stylesheet.b915ce98f9f65cca5e346b24fc336009b3608a3eeb24ce4b0e53c4500eba9374.css integrity="sha256-uRXOmPn2XMpeNGsk/DNgCbNgij7rJM5LDlPEUA66k3Q=" rel="preload stylesheet" as=style><link rel=icon href=https://litjohn.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://litjohn.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://litjohn.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://litjohn.github.io/apple-touch-icon.png><link rel=mask-icon href=https://litjohn.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://litjohn.github.io/posts/comfyui/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://litjohn.github.io/posts/comfyui/"><meta property="og:site_name" content="正确即是废话，废话亦是正确"><meta property="og:title" content="下载 ComfyUI 记录"><meta property="og:description" content=" 我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。 省流：垃圾
最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。
comfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。
主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。
我使用了它来运行 Z-image turbo。
下载非常简单。你需要访问官网，然后下载一个安装包。
有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。
下载之后无脑跟随指示。
然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。
可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。
之后点击 comfyUI.exe 启动。过程也很简单。
可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。
去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 modelscope。
实测这个仓库可用。
进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。
注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。
量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。
下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \models\ 中的 \diffusion_models，\text_encoders 和 \vae 中。
注意绝对不是 \ComfyUI\resources\ComfyUI\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-31T21:39:56+08:00"><meta property="article:modified_time" content="2026-01-31T21:39:56+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="下载 ComfyUI 记录"><meta name=twitter:description content="
我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。
省流：垃圾

最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。

comfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。
主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。
我使用了它来运行 Z-image turbo。

下载非常简单。你需要访问官网，然后下载一个安装包。
有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。
下载之后无脑跟随指示。
然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。
可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。

之后点击 comfyUI.exe 启动。过程也很简单。
可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。

去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 modelscope。
实测这个仓库可用。
进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。
注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。
量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。
下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \models\ 中的 \diffusion_models，\text_encoders 和 \vae 中。
注意绝对不是 \ComfyUI\resources\ComfyUI\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://litjohn.github.io/posts/"},{"@type":"ListItem","position":2,"name":"下载 ComfyUI 记录","item":"https://litjohn.github.io/posts/comfyui/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"下载 ComfyUI 记录","name":"下载 ComfyUI 记录","description":" 我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。 省流：垃圾\n最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。\ncomfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。\n主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。\n我使用了它来运行 Z-image turbo。\n下载非常简单。你需要访问官网，然后下载一个安装包。\n有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。\n下载之后无脑跟随指示。\n然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。\n可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。\n之后点击 comfyUI.exe 启动。过程也很简单。\n可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。\n去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 modelscope。\n实测这个仓库可用。\n进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。\n注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。\n量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。\n下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \\models\\ 中的 \\diffusion_models，\\text_encoders 和 \\vae 中。\n注意绝对不是 \\ComfyUI\\resources\\ComfyUI\\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。\n","keywords":[],"articleBody":" 我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。 省流：垃圾\n最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。\ncomfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。\n主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。\n我使用了它来运行 Z-image turbo。\n下载非常简单。你需要访问官网，然后下载一个安装包。\n有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。\n下载之后无脑跟随指示。\n然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。\n可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。\n之后点击 comfyUI.exe 启动。过程也很简单。\n可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。\n去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 modelscope。\n实测这个仓库可用。\n进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。\n注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。\n量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。\n下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \\models\\ 中的 \\diffusion_models，\\text_encoders 和 \\vae 中。\n注意绝对不是 \\ComfyUI\\resources\\ComfyUI\\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。\n就是那个目录。\n要跑起来还需要一份工作流。所幸工作流不需要自己写，可以找官方的示例。\n这个就挺好：https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_z_image_turbo.json\n用 comfyUI 打开它。提示少一个 lora，不影响。把右下角那些和 lora 相关的链路删掉即可，因为我们暂时不需要 lora。\n然后点击右上角的运行，等待若干时间让它出图。\n伏笔回收。你可能会遇到神秘报错。\n有可能是显卡驱动太老，和 pytorch 不兼容。这时需要升级驱动，具体流程问 AI 或者搜索。并不复杂。\n然后如果你的电脑上已经有了非常新版本的 Python 且设置了环境变量，可能会导致 comfyUI 配置 pytorch 时下的 Python 被遮蔽，而过于新版本的 Python 可能有兼容性问题。\n这时需要 pip 重装 pytorch。具体流程也去问 AI。\n按理说能出图了。当然，如果硬件过老，可能要等很久。\n并且需要把模型权重从硬盘加载进内存和显存，也挺费时间的。\n第一次运行之后模型权重会被缓存到内存和缓存里，之后就会快一些。显存占用持续高涨是正常的。\n建议至少 16GB 显存的显卡来跑全精度模型。全精度的质量确实比 4 位量化好得多。\n6GB 的 1060 也不是不能跑。但你需要忍受必须使用 4 位量化，而且 1024*1024 的图（4 步去噪）需要 3 分钟的现实。跑全精度模型会使得权重溢出到内存和虚拟内存中，并且一张图可能需要十分钟。\n","wordCount":"123","inLanguage":"en","datePublished":"2026-01-31T21:39:56+08:00","dateModified":"2026-01-31T21:39:56+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://litjohn.github.io/posts/comfyui/"},"publisher":{"@type":"Organization","name":"正确即是废话，废话亦是正确","logo":{"@type":"ImageObject","url":"https://litjohn.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://litjohn.github.io/ accesskey=h title="正确即是废话，废话亦是正确 (Alt + H)">正确即是废话，废话亦是正确</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://litjohn.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://litjohn.github.io/series/ title=系列><span>系列</span></a></li><li><a href=https://litjohn.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://litjohn.github.io/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">下载 ComfyUI 记录</h1><div class=post-meta><span title='2026-01-31 21:39:56 +0800 +0800'>January 31, 2026</span></div></header><div class=post-content><blockquote><p>我是 comfyUI 萌新。这篇文章不会有太多的技术干货，仅仅是下载和配置过程的记录。
省流：垃圾</p></blockquote><p>最近听说了 Z-image turbo。非常感兴趣，于是打算部署一发。</p><hr><p>comfyUI 是一款美观易用的本地部署应用。主要战场是扩散生图模型和视频生成，但同样支持 LLM。</p><p>主要特性是可以用图形化方式配置工作流（你可能想到了 scratch。没错，就是类似那样）。</p><p>我使用了它来运行 Z-image turbo。</p><hr><p>下载非常简单。你需要访问<a href=https://www.comfy.org/>官网</a>，然后下载一个安装包。</p><p>有人可能用的是 portable。但我选择了 for Windows 的那个打包好的版本。</p><p>下载之后无脑跟随指示。</p><p>然后会自动下载和配置 pytorch，大概会下载几个 G（pytorch 本体 2.4GB 左右）。</p><p>可能会遇到神秘报错。忽略即可。只要能跑通就不是问题。</p><hr><p>之后点击 comfyUI.exe 启动。过程也很简单。</p><p>可能会提示你选择一个目录放数据。这个目录建议选择空间大的盘符放，因为以后模型权重也要放在里面。</p><hr><p>去官网下载 Z-image turbo 的权重。hugging face 不能直连，所以选择 <a href=modelscope.cn>modelscope</a>。</p><p>实测这个<a href=https://www.modelscope.cn/models/Comfy-Org/z_image_turbo>仓库</a>可用。</p><p>进入模型文件一栏，在 split_file 中，分别从 vae、diffusion model 和 text encoder 中挑一个你中意的下载下来。</p><p>注意模型的名字标明了量化的程度。text encoder 中，最大的那个无后缀的模型是全精度的。diffusion model 中，BF16 后缀的是全精度的。</p><p>量化精度高的模型性能更好。但是会更加消耗显存和算力，所以根据硬件资源量力而行。否则生成速度可能会非常缓慢，并且大量动用虚拟内存，甚至直接崩掉。</p><p>下载的模型权重放在你之前选择的那个目录（比如叫做 comfyUI-data）下的 \models\ 中的 \diffusion_models，\text_encoders 和 \vae 中。</p><p>注意绝对不是 \ComfyUI\resources\ComfyUI\models。如果你忘记了之前选了哪个目录，你可以进入 comfyUI，点击图标打开菜单，然后选择帮助一栏下的“open folder”，“open model folder”（英文）或者“打开模型文件夹”（中文）。</p><p>就是那个目录。</p><hr><p>要跑起来还需要一份工作流。所幸工作流不需要自己写，可以找官方的示例。</p><p>这个就挺好：<a href=https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_z_image_turbo.json>https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_z_image_turbo.json</a></p><p>用 comfyUI 打开它。提示少一个 lora，不影响。把右下角那些和 lora 相关的链路删掉即可，因为我们暂时不需要 lora。</p><p>然后点击右上角的运行，等待若干时间让它出图。</p><hr><p>伏笔回收。你可能会遇到神秘报错。</p><p>有可能是显卡驱动太老，和 pytorch 不兼容。这时需要升级驱动，具体流程问 AI 或者搜索。并不复杂。</p><p>然后如果你的电脑上已经有了非常新版本的 Python 且设置了环境变量，可能会导致 comfyUI 配置 pytorch 时下的 Python 被遮蔽，而过于新版本的 Python 可能有兼容性问题。</p><p>这时需要 pip 重装 pytorch。具体流程也去问 AI。</p><hr><p>按理说能出图了。当然，如果硬件过老，可能要等很久。</p><p>并且需要把模型权重从硬盘加载进内存和显存，也挺费时间的。</p><p>第一次运行之后模型权重会被缓存到内存和缓存里，之后就会快一些。显存占用持续高涨是正常的。</p><p>建议至少 16GB 显存的显卡来跑全精度模型。全精度的质量确实比 4 位量化好得多。</p><p>6GB 的 1060 也不是不能跑。但你需要忍受必须使用 4 位量化，而且 1024*1024 的图（4 步去噪）需要 3 分钟的现实。跑全精度模型会使得权重溢出到内存和虚拟内存中，并且一张图可能需要十分钟。</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://litjohn.github.io/>正确即是废话，废话亦是正确</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>